{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxWXk7KjG14x"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WgA1YAfG145"
      },
      "source": [
        "\n",
        "# Hello, NAS!\n",
        "\n",
        "This is the 101 tutorial of Neural Architecture Search (NAS) on NNI.\n",
        "In this tutorial, we will search for a neural architecture on MNIST dataset with the help of NAS framework of NNI, i.e., *Retiarii*.\n",
        "We use multi-trial NAS as an example to show how to construct and explore a model space.\n",
        "\n",
        "There are mainly three crucial components for a neural architecture search task, namely,\n",
        "\n",
        "* Model search space that defines a set of models to explore.\n",
        "* A proper strategy as the method to explore this model space.\n",
        "* A model evaluator that reports the performance of every model in the space.\n",
        "\n",
        "Currently, PyTorch is the only supported framework by Retiarii, and we have only tested **PyTorch 1.7 to 1.10**.\n",
        "This tutorial assumes PyTorch context but it should also apply to other frameworks, which is in our future plan.\n",
        "\n",
        "## Define your Model Space\n",
        "\n",
        "Model space is defined by users to express a set of models that users want to explore, which contains potentially good-performing models.\n",
        "In this framework, a model space is defined with two parts: a base model and possible mutations on the base model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBTxrGYXG15B"
      },
      "source": [
        "### Define Base Model\n",
        "\n",
        "Defining a base model is almost the same as defining a PyTorch (or TensorFlow) model.\n",
        "Usually, you only need to replace the code ``import torch.nn as nn`` with\n",
        "``import nni.retiarii.nn.pytorch as nn`` to use our wrapped PyTorch modules.\n",
        "\n",
        "Below is a very simple example of defining a base model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#! pip install nni==2.9\n",
        "! pip install pytorch_lightning"
      ],
      "metadata": {
        "id": "RqHa60q0HJvw",
        "outputId": "13e30c03-7eea-44cb-b07e-7366b2c0344a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-2.5.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>5.4 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2025.3.0)\n",
            "Collecting torchmetrics>0.7.0 (from pytorch_lightning)\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (25.0)\n",
            "Requirement already satisfied: typing-extensions>4.5.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (4.15.0)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch_lightning)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.12.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.19.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.4.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics>0.7.0->pytorch_lightning) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.20.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.1.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.1.0->pytorch_lightning) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.10)\n",
            "Downloading pytorch_lightning-2.5.5-py3-none-any.whl (832 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.4/832.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch_lightning\n",
            "Successfully installed lightning-utilities-0.15.2 pytorch_lightning-2.5.5 torchmetrics-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KNPY6LIuG15D",
        "outputId": "8eab599f-e5e3-4695-d311-e2764cae2465",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/nni/nas/nn/pytorch/layers.py:89: RuntimeWarning: <class 'torch.nn.parameter.Buffer'> is found to be not a nn.Module, which is unexpected. It means your PyTorch version might not be supported.\n",
            "  warnings.warn(f'{obj} is found to be not a nn.Module, which is unexpected. '\n",
            "/usr/local/lib/python3.12/dist-packages/nni/common/serializer.py:618: FutureWarning: `NLLLoss2d` has been deprecated. Please use `NLLLoss` instead as a drop-in replacement and see https://pytorch.org/docs/main/nn.html#torch.nn.NLLLoss for more details.\n",
            "  return super().__new__(cls, name, cast(Tuple[type, ...], bases), dct)\n",
            "/usr/local/lib/python3.12/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import nni.retiarii.nn.pytorch as nn\n",
        "from nni.retiarii import model_wrapper\n",
        "\n",
        "\n",
        "@model_wrapper      # this decorator should be put on the out most\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(9216, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(self.conv2(x), 2)\n",
        "        x = torch.flatten(self.dropout1(x), 1)\n",
        "        x = self.fc2(self.dropout2(F.relu(self.fc1(x))))\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2y9CoA-G15J"
      },
      "source": [
        ".. tip:: Always keep in mind that you should use ``import nni.retiarii.nn.pytorch as nn`` and :meth:`nni.retiarii.model_wrapper`.\n",
        "         Many mistakes are a result of forgetting one of those.\n",
        "         Also, please use ``torch.nn`` for submodules of ``nn.init``, e.g., ``torch.nn.init`` instead of ``nn.init``.\n",
        "\n",
        "### Define Model Mutations\n",
        "\n",
        "A base model is only one concrete model not a model space. We provide :doc:`API and Primitives </nas/construct_space>`\n",
        "for users to express how the base model can be mutated. That is, to build a model space which includes many models.\n",
        "\n",
        "Based on the above base model, we can define a model space as below.\n",
        "\n",
        ".. code-block:: diff\n",
        "\n",
        "  @model_wrapper\n",
        "  class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "      self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "  -   self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "  +   self.conv2 = nn.LayerChoice([\n",
        "  +       nn.Conv2d(32, 64, 3, 1),\n",
        "  +       DepthwiseSeparableConv(32, 64)\n",
        "  +   ])\n",
        "  -   self.dropout1 = nn.Dropout(0.25)\n",
        "  +   self.dropout1 = nn.Dropout(nn.ValueChoice([0.25, 0.5, 0.75]))\n",
        "      self.dropout2 = nn.Dropout(0.5)\n",
        "  -   self.fc1 = nn.Linear(9216, 128)\n",
        "  -   self.fc2 = nn.Linear(128, 10)\n",
        "  +   feature = nn.ValueChoice([64, 128, 256])\n",
        "  +   self.fc1 = nn.Linear(9216, feature)\n",
        "  +   self.fc2 = nn.Linear(feature, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = F.relu(self.conv1(x))\n",
        "      x = F.max_pool2d(self.conv2(x), 2)\n",
        "      x = torch.flatten(self.dropout1(x), 1)\n",
        "      x = self.fc2(self.dropout2(F.relu(self.fc1(x))))\n",
        "      output = F.log_softmax(x, dim=1)\n",
        "      return output\n",
        "\n",
        "This results in the following code:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ekWP6fcVG15K",
        "outputId": "9322a32b-b08d-404b-a62c-23b0118dc635",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelSpace(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): LayerChoice([Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1)), DepthwiseSeparableConv(\n",
              "    (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32)\n",
              "    (pointwise): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )], label='model_1')\n",
              "  (dropout1): Dropout(p=0.25, inplace=False)\n",
              "  (dropout2): Dropout(p=0.5, inplace=False)\n",
              "  (fc1): Linear(in_features=9216, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "class DepthwiseSeparableConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.depthwise = nn.Conv2d(in_ch, in_ch, kernel_size=3, groups=in_ch)\n",
        "        self.pointwise = nn.Conv2d(in_ch, out_ch, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.pointwise(self.depthwise(x))\n",
        "\n",
        "\n",
        "@model_wrapper\n",
        "class ModelSpace(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        # LayerChoice is used to select a layer between Conv2d and DwConv.\n",
        "        self.conv2 = nn.LayerChoice([\n",
        "            nn.Conv2d(32, 64, 3, 1),\n",
        "            DepthwiseSeparableConv(32, 64)\n",
        "        ])\n",
        "        # ValueChoice is used to select a dropout rate.\n",
        "        # ValueChoice can be used as parameter of modules wrapped in `nni.retiarii.nn.pytorch`\n",
        "        # or customized modules wrapped with `@basic_unit`.\n",
        "        self.dropout1 = nn.Dropout(nn.ValueChoice([0.25, 0.5, 0.75]))  # choose dropout rate from 0.25, 0.5 and 0.75\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        feature = nn.ValueChoice([64, 128, 256])\n",
        "        self.fc1 = nn.Linear(9216, feature)\n",
        "        self.fc2 = nn.Linear(feature, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(self.conv2(x), 2)\n",
        "        x = torch.flatten(self.dropout1(x), 1)\n",
        "        x = self.fc2(self.dropout2(F.relu(self.fc1(x))))\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "\n",
        "model_space = ModelSpace()\n",
        "model_space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wyA2Hj0G15L"
      },
      "source": [
        "This example uses two mutation APIs,\n",
        ":class:`nn.LayerChoice <nni.retiarii.nn.pytorch.LayerChoice>` and\n",
        ":class:`nn.InputChoice <nni.retiarii.nn.pytorch.ValueChoice>`.\n",
        ":class:`nn.LayerChoice <nni.retiarii.nn.pytorch.LayerChoice>`\n",
        "takes a list of candidate modules (two in this example), one will be chosen for each sampled model.\n",
        "It can be used like normal PyTorch module.\n",
        ":class:`nn.InputChoice <nni.retiarii.nn.pytorch.ValueChoice>` takes a list of candidate values,\n",
        "one will be chosen to take effect for each sampled model.\n",
        "\n",
        "More detailed API description and usage can be found :doc:`here </nas/construct_space>`.\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Note</h4><p>We are actively enriching the mutation APIs, to facilitate easy construction of model space.\n",
        "    If the currently supported mutation APIs cannot express your model space,\n",
        "    please refer to :doc:`this doc </nas/mutator>` for customizing mutators.</p></div>\n",
        "\n",
        "## Explore the Defined Model Space\n",
        "\n",
        "There are basically two exploration approaches: (1) search by evaluating each sampled model independently,\n",
        "which is the search approach in `multi-trial NAS <multi-trial-nas>`\n",
        "and (2) one-shot weight-sharing based search, which is used in one-shot NAS.\n",
        "We demonstrate the first approach in this tutorial. Users can refer to `here <one-shot-nas>` for the second approach.\n",
        "\n",
        "First, users need to pick a proper exploration strategy to explore the defined model space.\n",
        "Second, users need to pick or customize a model evaluator to evaluate the performance of each explored model.\n",
        "\n",
        "### Pick an exploration strategy\n",
        "\n",
        "Retiarii supports many :doc:`exploration strategies </nas/exploration_strategy>`.\n",
        "\n",
        "Simply choosing (i.e., instantiate) an exploration strategy as below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Hqk4NftnG15M"
      },
      "outputs": [],
      "source": [
        "import nni.retiarii.strategy as strategy\n",
        "search_strategy = strategy.Random(dedup=True)  # dedup=False if deduplication is not wanted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c78jBkD_G15N"
      },
      "source": [
        "### Pick or customize a model evaluator\n",
        "\n",
        "In the exploration process, the exploration strategy repeatedly generates new models. A model evaluator is for training\n",
        "and validating each generated model to obtain the model's performance.\n",
        "The performance is sent to the exploration strategy for the strategy to generate better models.\n",
        "\n",
        "Retiarii has provided :doc:`built-in model evaluators </nas/evaluator>`, but to start with,\n",
        "it is recommended to use :class:`FunctionalEvaluator <nni.retiarii.evaluator.FunctionalEvaluator>`,\n",
        "that is, to wrap your own training and evaluation code with one single function.\n",
        "This function should receive one single model class and uses :func:`nni.report_final_result` to report the final score of this model.\n",
        "\n",
        "An example here creates a simple evaluator that runs on MNIST dataset, trains for 2 epochs, and reports its validation accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4O9FQ8VrG15O"
      },
      "outputs": [],
      "source": [
        "import nni\n",
        "\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "def train_epoch(model, device, train_loader, optimizer, epoch):\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = loss_fn(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test_epoch(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "          correct, len(test_loader.dataset), accuracy))\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "def evaluate_model(model_cls):\n",
        "    # \"model_cls\" is a class, need to instantiate\n",
        "    model = model_cls()\n",
        "\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    transf = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "    train_loader = DataLoader(MNIST('data/mnist', download=True, transform=transf), batch_size=64, shuffle=True)\n",
        "    test_loader = DataLoader(MNIST('data/mnist', download=True, train=False, transform=transf), batch_size=64)\n",
        "\n",
        "    for epoch in range(3):\n",
        "        # train the model for one epoch\n",
        "        train_epoch(model, device, train_loader, optimizer, epoch)\n",
        "        # test the model for one epoch\n",
        "        accuracy = test_epoch(model, device, test_loader)\n",
        "        # call report intermediate result. Result can be float or dict\n",
        "        nni.report_intermediate_result(accuracy)\n",
        "\n",
        "    # report final test result\n",
        "    nni.report_final_result(accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2i6dNVOGG15P"
      },
      "source": [
        "Create the evaluator\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sJbteVSkG15V"
      },
      "outputs": [],
      "source": [
        "from nni.retiarii.evaluator import FunctionalEvaluator\n",
        "evaluator = FunctionalEvaluator(evaluate_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4Ysqq3OG15W"
      },
      "source": [
        "The ``train_epoch`` and ``test_epoch`` here can be any customized function,\n",
        "where users can write their own training recipe.\n",
        "\n",
        "It is recommended that the ``evaluate_model`` here accepts no additional arguments other than ``model_cls``.\n",
        "However, in the :doc:`advanced tutorial </nas/evaluator>`, we will show how to use additional arguments in case you actually need those.\n",
        "In future, we will support mutation on the arguments of evaluators, which is commonly called \"Hyper-parmeter tuning\".\n",
        "\n",
        "## Launch an Experiment\n",
        "\n",
        "After all the above are prepared, it is time to start an experiment to do the model search. An example is shown below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SMNNTcU7G15W"
      },
      "outputs": [],
      "source": [
        "from nni.retiarii.experiment.pytorch import RetiariiExperiment, RetiariiExeConfig\n",
        "exp = RetiariiExperiment(model_space, evaluator, [], search_strategy)\n",
        "exp_config = RetiariiExeConfig('local')\n",
        "exp_config.experiment_name = 'mnist_search'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUgk1WSmG15X"
      },
      "source": [
        "The following configurations are useful to control how many trials to run at most / at the same time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sHj5ks-qG15X"
      },
      "outputs": [],
      "source": [
        "exp_config.max_trial_number = 4   # spawn 4 trials at most\n",
        "exp_config.trial_concurrency = 2  # will run two trials concurrently"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUvpufPgG15Y"
      },
      "source": [
        "Remember to set the following config if you want to GPU.\n",
        "``use_active_gpu`` should be set true if you wish to use an occupied GPU (possibly running a GUI).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "aTJY0VPFG15Z"
      },
      "outputs": [],
      "source": [
        "exp_config.trial_gpu_number = 1\n",
        "exp_config.training_service.use_active_gpu = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpKDt3MPG15Z"
      },
      "source": [
        "Launch the experiment. The experiment should take several minutes to finish on a workstation with 2 GPUs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ysIYNfM8G15a",
        "outputId": "7823f7b6-31e3-4718-cb20-ddbfd0ce2ded",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "RetiariiExeConfig: type of experiment_name ('mnist_search') is not typing.Optional[str]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-840297264.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8081\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nni/nas/experiment/pytorch.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, config, port, debug)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0mws_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'ws://localhost:{port}/tuner'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0mcanoni_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBackground\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mws_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'retiarii'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mcanoni_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRetiariiExeConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanoni_conf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetiariiAdvisor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nni/experiment/experiment.py\u001b[0m in \u001b[0;36m_start_impl\u001b[0;34m(self, port, debug, run_mode, tuner_command_channel, tags)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0matexit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonical_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_annotation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NNI annotation is not supported by Python experiment API.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nni/experiment/config/base.py\u001b[0m in \u001b[0;36mcanonical_copy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mcanon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mcanon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_canonicalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mcanon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_canonical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcanon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nni/experiment/config/experiment_config.py\u001b[0m in \u001b[0;36m_validate_canonical\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_canonical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_canonical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mspace_cnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_space\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_space_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nni/experiment/config/base.py\u001b[0m in \u001b[0;36m_validate_canonical\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;36m2.\u001b[0m \u001b[0mCall\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0m_validate_canonical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mon\u001b[0m \u001b[0mchildren\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0mobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincluding\u001b[0m \u001b[0mthose\u001b[0m \u001b[0minside\u001b[0m \u001b[0mlist\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \"\"\"\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nni/experiment/config/utils/internal.py\u001b[0m in \u001b[0;36mvalidate_type\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{class_name}: {field.name} is not set'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{class_name}: type of {field.name} ({repr(value)}) is not {field.type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_path_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_hint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: RetiariiExeConfig: type of experiment_name ('mnist_search') is not typing.Optional[str]"
          ]
        }
      ],
      "source": [
        "exp.run(exp_config, 8081)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaNSdkPsG15g"
      },
      "source": [
        "Users can also run Retiarii Experiment with :doc:`different training services </experiment/training_service/overview>`\n",
        "besides ``local`` training service.\n",
        "\n",
        "## Visualize the Experiment\n",
        "\n",
        "Users can visualize their experiment in the same way as visualizing a normal hyper-parameter tuning experiment.\n",
        "For example, open ``localhost:8081`` in your browser, 8081 is the port that you set in ``exp.run``.\n",
        "Please refer to :doc:`here </experiment/web_portal/web_portal>` for details.\n",
        "\n",
        "We support visualizing models with 3rd-party visualization engines (like `Netron <https://netron.app/>`__).\n",
        "This can be used by clicking ``Visualization`` in detail panel for each trial.\n",
        "Note that current visualization is based on `onnx <https://onnx.ai/>`__ ,\n",
        "thus visualization is not feasible if the model cannot be exported into onnx.\n",
        "\n",
        "Built-in evaluators (e.g., Classification) will automatically export the model into a file.\n",
        "For your own evaluator, you need to save your file into ``$NNI_OUTPUT_DIR/model.onnx`` to make this work.\n",
        "For instance,\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_P0f9mEBG15h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def evaluate_model_with_visualization(model_cls):\n",
        "    model = model_cls()\n",
        "    # dump the model into an onnx\n",
        "    if 'NNI_OUTPUT_DIR' in os.environ:\n",
        "        dummy_input = torch.zeros(1, 3, 32, 32)\n",
        "        torch.onnx.export(model, (dummy_input, ),\n",
        "                          Path(os.environ['NNI_OUTPUT_DIR']) / 'model.onnx')\n",
        "    evaluate_model(model_cls)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuarYH8qG15h"
      },
      "source": [
        "Relaunch the experiment, and a button is shown on Web portal.\n",
        "\n",
        "<img src=\"file://../../img/netron_entrance_webui.png\">\n",
        "\n",
        "## Export Top Models\n",
        "\n",
        "Users can export top models after the exploration is done using ``export_top_models``.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Pa-wajEwG15i",
        "outputId": "a5a94b71-3c93-4e52-b234-34faaf6a4438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "You need to set execution engine, before using it.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nni/nas/experiment/pytorch.py\u001b[0m in \u001b[0;36mexport_top_models\u001b[0;34m(self, top_k, optimize_mode, formatter)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# this currently works for one-shot algorithms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_top_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nni/nas/strategy/base.py\u001b[0m in \u001b[0;36mexport_top_models\u001b[0;34m(self, top_k)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexport_top_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\"export_top_models\" is not implemented.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m: \"export_top_models\" is not implemented.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1620535017.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mmodel_dict\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_top_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nni/nas/experiment/pytorch.py\u001b[0m in \u001b[0;36mexport_top_models\u001b[0;34m(self, top_k, optimize_mode, formatter)\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0;31m# when strategy hasn't implemented its own export logic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m             \u001b[0mall_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0moptimize_mode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'minimize'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0mall_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimize_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nni/nas/execution/api.py\u001b[0m in \u001b[0;36mlist_models\u001b[0;34m(*models)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlist_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_execution_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0mget_and_register_default_listener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nni/nas/execution/api.py\u001b[0m in \u001b[0;36mget_execution_engine\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_execution_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAbstractExecutionEngine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_execution_engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0m_execution_engine\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'You need to set execution engine, before using it.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_execution_engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: You need to set execution engine, before using it."
          ]
        }
      ],
      "source": [
        "for model_dict in exp.export_top_models(formatter='dict'):\n",
        "    print(model_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCQ1rKRAG15j"
      },
      "source": [
        "The output is ``json`` object which records the mutation actions of the top model.\n",
        "If users want to output source code of the top model,\n",
        "they can use `graph-based execution engine <graph-based-execution-engine>` for the experiment,\n",
        "by simply adding the following two lines.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rzF7XxU_G15j"
      },
      "outputs": [],
      "source": [
        "exp_config.execution_engine = 'base'\n",
        "export_formatter = 'code'"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jRIJhw7sW_J-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}